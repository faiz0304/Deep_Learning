{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c97e18-d592-4454-8d4b-ffcaa0244b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "824500bb-2fcd-41aa-b2a7-5a77e6f8e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "# from keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e69f244-9ce3-4f63-bef5-2d2ed6ce5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# https://faroit.com/keras-docs/1.2.0/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "270f8e68-ab83-4389-8027-0fd2b3072cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d4e626a-000e-497a-8e2d-7a9ae308f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer with Input & Convolution\n",
    "cnn.add(Conv2D(32,(3,3), input_shape=(64,64,3), activation=\"relu\")) # Conv2D(filter, kernel, input_shape=(size,kernel_channel_means_RGB)\n",
    "# Pooling\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layers with Convolution & Pooling\n",
    "cnn.add(Conv2D(16,(3,3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8fe730c-5b41-4325-b84e-0fd2f153ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers With ANN Network\n",
    "cnn.add(Dense(64, activation=\"relu\"))\n",
    "cnn.add(Dense(32, activation=\"relu\"))\n",
    "cnn.add(Dense(16, activation=\"relu\"))\n",
    "cnn.add(Dense(8, activation=\"relu\"))\n",
    "cnn.add(Dense(4, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43cd171d-07a1-47b5-8470-cc57e1c534eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dfc0baa-48cc-4647-8215-68183d6804c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 320ms/step - loss: 0.6928 - val_loss: 0.6917\n",
      "Epoch 2/5\n",
      "\u001b[1m 50/200\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 288ms/step - loss: 0.6917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Deep_Learning_WS_Cube_Tech\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 105ms/step - loss: 0.6906 - val_loss: 0.6917\n",
      "Epoch 3/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 341ms/step - loss: 0.6638 - val_loss: 0.6326\n",
      "Epoch 4/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - loss: 0.6452 - val_loss: 0.6116\n",
      "Epoch 5/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 349ms/step - loss: 0.6136 - val_loss: 0.5954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b27ed69180>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://faroit.com/keras-docs/1.2.0/preprocessing/image/\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'D:\\Deep_Learning_WS_Cube_Tech\\Convolutional_Neural_Network_CNN\\dog vs cat\\dataset\\training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r'D:\\Deep_Learning_WS_Cube_Tech\\Convolutional_Neural_Network_CNN\\dog vs cat\\dataset\\test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# cnn.fit_generator(\n",
    "cnn.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=200, # samples_per_epoch-old\n",
    "        epochs=5, #nb_epoch-old\n",
    "        validation_data=test_generator) #         nb_val_samples=800 - remove for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae368413-3c1f-4d6e-96bf-5a4faca71775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "defe5301-4e9a-46c6-b265-9b1586d8410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(r'D:\\Deep_Learning_WS_Cube_Tech\\Convolutional_Neural_Network_CNN\\dog vs cat\\dataset\\test_set\\cats\\cat.4001.jpg', target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a33f1175-20d4-4de5-aba8-e4ba03a91d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9369937a-c520-4f84-ad9b-29d590fe6eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 46.,  42.,  31.],\n",
       "        [ 34.,  24.,  22.],\n",
       "        [ 83.,  69.,  58.],\n",
       "        ...,\n",
       "        [136., 137., 142.],\n",
       "        [149., 150., 155.],\n",
       "        [144., 144., 152.]],\n",
       "\n",
       "       [[190., 161., 129.],\n",
       "        [200., 164., 138.],\n",
       "        [151., 122.,  92.],\n",
       "        ...,\n",
       "        [137., 138., 143.],\n",
       "        [152., 153., 158.],\n",
       "        [147., 147., 155.]],\n",
       "\n",
       "       [[ 76.,  60.,  44.],\n",
       "        [ 48.,  35.,  29.],\n",
       "        [ 69.,  55.,  42.],\n",
       "        ...,\n",
       "        [143., 144., 149.],\n",
       "        [153., 154., 159.],\n",
       "        [144., 147., 154.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[154., 122., 101.],\n",
       "        [155., 123., 102.],\n",
       "        [148., 116.,  95.],\n",
       "        ...,\n",
       "        [159., 135., 123.],\n",
       "        [162., 138., 126.],\n",
       "        [159., 134., 127.]],\n",
       "\n",
       "       [[156., 123., 104.],\n",
       "        [147., 114.,  95.],\n",
       "        [169., 136., 117.],\n",
       "        ...,\n",
       "        [160., 136., 126.],\n",
       "        [160., 136., 126.],\n",
       "        [170., 145., 140.]],\n",
       "\n",
       "       [[153., 120., 103.],\n",
       "        [150., 117., 100.],\n",
       "        [147., 114.,  97.],\n",
       "        ...,\n",
       "        [164., 139., 134.],\n",
       "        [161., 136., 131.],\n",
       "        [155., 135., 128.]]], shape=(64, 64, 3), dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f74d69bd-69be-4962-82d3-545585735cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2015ea79-839f-4e06-b2ec-475578d76d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d71cabd-3794-4bd2-bdc5-a121380233e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = cnn.predict(img)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0dd14a7-91f5-4fc3-8607-7d81242d6156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "if p[0][0] < 0.5:\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"Cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a9432-620c-477e-8ab5-dd412dcd5635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
